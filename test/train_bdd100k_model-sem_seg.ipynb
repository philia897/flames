{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "from lib.data import tools\n",
    "reload(tools)\n",
    "from lib.data.tools import get_dataloader\n",
    "from lib.train.runners import PytorchRunner\n",
    "from lib.train.metrics import IoUMetricMeter\n",
    "from models.modelInterface import BDD100kModel\n",
    "import lib.simulation.env\n",
    "reload(lib.simulation.env)\n",
    "from lib.simulation.env import (get_image_paths, get_label_paths, get_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "pkg_name = \"10k\" # 100k or 10k\n",
    "output_size = (512,1024)\n",
    "task_name = \"sem_seg\" # \"drivable\", \"sem_seg\"\n",
    "config_file = \"/home/zekun/drivable/src/models/sem_seg/config-deeplabv3plus-sem_seg.py\"\n",
    "checkpoint_file = \"/home/zekun/drivable/outputs/semantic/db/models/deeplabv3+_r50-d8_512x1024_80k_sem_seg_bdd100k.pth\"\n",
    "new_checkpoint_file = \"/home/zekun/drivable/outputs/semantic/db/models/deeplabv3+_backbone-test.pth\"\n",
    "train_attr_file = f\"/home/zekun/drivable/data/bdd100k/labels/{pkg_name}/bdd100k_labels_images_attributes_train.json\"\n",
    "val_attr_file = f\"/home/zekun/drivable/data/bdd100k/labels/{pkg_name}/bdd100k_labels_images_attributes_val.json\"\n",
    "output_dir = \"/home/zekun/drivable/outputs/semantic\"\n",
    "\n",
    "batchsize = 4\n",
    "learn_rate = 1e-4\n",
    "epochs = 10\n",
    "num_workers = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH, IMAGE_PATH_TRAIN, IMAGE_PATH_VAL = get_image_paths(\"/home/zekun/drivable/\", pkg_name)\n",
    "LABEL_PATH, LABEL_PATH_TRAIN, LABEL_PATH_VAL = get_label_paths(\"/home/zekun/drivable/\", task_name, pkg_name)\n",
    "train_transform = get_transforms(task_name, output_size, \"train\")\n",
    "val_transform = get_transforms(task_name, output_size, \"test\")\n",
    "classes_num = 19\n",
    "\n",
    "conditions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.data.condparser import BDD100KConditionParser, ConditionParserMode\n",
    "import json\n",
    "\n",
    "all_conditions = tools.get_all_appeared_conditions(val_attr_file, ConditionParserMode.VALUE_LIST)\n",
    "\n",
    "conditions = []\n",
    "for condition in all_conditions:\n",
    "    if \"snowy\" in condition or \"rainy\" in condition:\n",
    "        conditions.append(condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "846\n",
      "133\n"
     ]
    }
   ],
   "source": [
    "train_fns = tools.get_img_paths_by_conditions(conditions, train_attr_file, IMAGE_PATH_TRAIN)\n",
    "val_fns = tools.get_img_paths_by_conditions(conditions, val_attr_file, IMAGE_PATH_VAL)\n",
    "\n",
    "train_loader = get_dataloader(\n",
    "    train_fns,\n",
    "    batch_size=batchsize,\n",
    "    workers=num_workers,\n",
    "    transform=train_transform,\n",
    "    img_path=IMAGE_PATH_TRAIN,\n",
    "    lbl_path=LABEL_PATH_TRAIN,\n",
    "    is_train=True,\n",
    ")\n",
    "val_loader = get_dataloader(\n",
    "    val_fns,\n",
    "    batch_size=batchsize,\n",
    "    workers=num_workers,\n",
    "    transform=val_transform,\n",
    "    img_path=IMAGE_PATH_VAL,\n",
    "    lbl_path=LABEL_PATH_VAL,        \n",
    "    is_train=False,\n",
    ")\n",
    "\n",
    "print(len(train_fns))\n",
    "print(len(val_fns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BDD100kModel(backbone=tools.load_mmcv_checkpoint(config_file, checkpoint_file))\n",
    "# tools.load_checkpoint(model, checkpoint_file)\n",
    "# tools.save_model(model.backbone, checkpoint_file)\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), lr=learn_rate)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learn_rate, momentum=0.9, weight_decay=0.0005)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=255)\n",
    "\n",
    "runner = PytorchRunner(optimizer, criterion, train_loader, val_loader, IoUMetricMeter(classes_num), DEVICE, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runner.train(model, epochs)\n",
    "for i in range(epochs)\n",
    "    train_log = runner.train(model)\n",
    "    print(f\"Train: loss={train_log['loss']}, pAcc={train_log['pAcc']}, mIoU={train_log['mIoU']}\")\n",
    "    train_log = runner.validate(model)\n",
    "    print(f\"Validate: loss={train_log['loss']}, pAcc={train_log['pAcc']}, mIoU={train_log['mIoU']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Valid: 100%|██████████| 34/34 [00:11<00:00,  2.90it/s, loss=0.31, pAcc=0.919] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.31038389058041393, 'pAcc': 0.918601328211798, 'mIoU': 0.6038449005651612, 'Acc': [0.9724636586155133, 0.7772915426521523, 0.8889251096569247, 0.4004800461343038, 0.859280898155459, 0.8028688829214464, 0.8244922993815872, 0.8830381261444189, 0.9225955646178019, 0.6433837160233672, 0.9682988168505482, 0.808794401162023, 0.9224801428483468, 0.9174735886385387, 0.7903437843182594, 0.9080582125002448, 0.0, 0.0], 'IoU': [0.9424369845420645, 0.6475604461791583, 0.8391755246753493, 0.17805028185231425, 0.6177647950261956, 0.5520584683509385, 0.7046915955272334, 0.7154117880337528, 0.8600042310424069, 0.5097171635175117, 0.9323175629856202, 0.6892724147808651, 0.5594055709058323, 0.8837172889121037, 0.5912744708968375, 0.6463496229447152, 0.0, 0.0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "valid_logs = runner.validate(model)\n",
    "print(valid_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.31038389058041393\n",
      "pAcc = 0.918601328211798\n",
      "mIoU = 0.6038449005651612\n",
      "Acc = [0.9724636586155133, 0.7772915426521523, 0.8889251096569247, 0.4004800461343038, 0.859280898155459, 0.8028688829214464, 0.8244922993815872, 0.8830381261444189, 0.9225955646178019, 0.6433837160233672, 0.9682988168505482, 0.808794401162023, 0.9224801428483468, 0.9174735886385387, 0.7903437843182594, 0.9080582125002448, 0.0, 0.0]\n",
      "IoU = [0.9424369845420645, 0.6475604461791583, 0.8391755246753493, 0.17805028185231425, 0.6177647950261956, 0.5520584683509385, 0.7046915955272334, 0.7154117880337528, 0.8600042310424069, 0.5097171635175117, 0.9323175629856202, 0.6892724147808651, 0.5594055709058323, 0.8837172889121037, 0.5912744708968375, 0.6463496229447152, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "for k,v in valid_logs.items():\n",
    "    print(k, \"=\", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tools' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/zekun/drivable/test/train_bdd100k_model-sem_seg.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Btlab.server/home/zekun/drivable/test/train_bdd100k_model-sem_seg.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m tools\u001b[39m.\u001b[39msave_model(model\u001b[39m.\u001b[39mbackbone, new_checkpoint_file, epochs, valid_logs[\u001b[39m'\u001b[39m\u001b[39mmIoU\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tools' is not defined"
     ]
    }
   ],
   "source": [
    "tools.save_model(model.backbone, new_checkpoint_file, epochs, valid_logs['mIoU'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.8333263889467588\n",
      "0.0\n",
      "mIoU: 0.2777754629822529\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "x1 = [1,1,1]\n",
    "x2 = [1,1,2]\n",
    "\n",
    "def calculate_iou(pred_mask, true_mask, class_label):\n",
    "    pred_class = pred_mask == class_label\n",
    "    true_class = true_mask == class_label\n",
    "\n",
    "    intersection = np.logical_and(pred_class, true_class)\n",
    "    union = np.logical_or(pred_class, true_class)\n",
    "\n",
    "    iou_score = np.sum(intersection) / (np.sum(union) + 0.00005)\n",
    "    return iou_score\n",
    "\n",
    "def calculate_mean_iou(pred_mask, true_mask, num_classes):\n",
    "    miou_sum = 0.0\n",
    "    for class_label in range(num_classes):\n",
    "        iou = calculate_iou(pred_mask, true_mask, class_label)\n",
    "        print(iou)\n",
    "        miou_sum += iou\n",
    "\n",
    "    mean_iou = miou_sum / num_classes\n",
    "    return mean_iou\n",
    "\n",
    "num_classes = 3\n",
    "miou = calculate_mean_iou(np.array([x1, x1]), np.array([x2, x1]), num_classes)\n",
    "print(\"mIoU:\", miou)\n",
    "print(x1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 1024])\n",
      "torch.Size([512, 1024])\n",
      "torch.Size([3, 512, 1024]) torch.Size([512, 1024])\n",
      "tensor([[0.0078, 0.0078, 0.0078,  ..., 0.0392, 0.0392, 0.0392],\n",
      "        [0.0078, 0.0078, 0.0078,  ..., 0.0392, 0.0392, 0.0392],\n",
      "        [0.0078, 0.0078, 0.0078,  ..., 0.0392, 0.0392, 0.0392],\n",
      "        ...,\n",
      "        [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "# from importlib import reload\n",
    "# from mmseg.apis import inference_model, init_model, show_result_pyplot\n",
    "# from mmengine.config import Config\n",
    "# from mmengine.runner import load_checkpoint\n",
    "# from collections import defaultdict\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import torch\n",
    "\n",
    "# from PIL import Image\n",
    "# from bdd100k.label.palette import get_palette\n",
    "# import lib.simulation.env\n",
    "# reload(lib.simulation.env)\n",
    "# from lib.simulation.env import get_transforms\n",
    "# import models.modelInterface\n",
    "# reload(models.modelInterface)\n",
    "# from models.modelInterface import BDD100kModel\n",
    "# from lib.data.tools import load_mmcv_checkpoint\n",
    "\n",
    "# config_file = \"/home/zekun/drivable/src/models/sem_seg/config-deeplabv3plus-sem_seg.py\"\n",
    "# checkpoint_file = \"/home/zekun/drivable/outputs/semantic/db/models/deeplabv3+_r50-d8_512x1024_80k_sem_seg_bdd100k.pth\"\n",
    "# image_name = \"../data/bdd100k/images/10k/val/7d06fefd-f7be05a6.jpg\"\n",
    "# label_name = \"../data/bdd100k/labels/10k/sem_seg/masks/val/7d06fefd-f7be05a6.png\"\n",
    "\n",
    "# model = BDD100kModel(load_mmcv_checkpoint(config_file, checkpoint_file))\n",
    "# model.eval()\n",
    "\n",
    "# output_size = (512,1024)\n",
    "\n",
    "# transform = get_transforms(\"sem_seg\", output_size, \"train\")\n",
    "\n",
    "# data = transform(Image.open(image_name), Image.open(label_name))\n",
    "\n",
    "# print(data[0].shape[-2:])\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     results = model(data[0].unsqueeze(0))\n",
    "#     results = torch.argmax(results, dim=1).squeeze().detach().cpu()\n",
    "# print(results.shape)\n",
    "\n",
    "# print(data[0].shape, data[1].shape)\n",
    "# print(data[1])\n",
    "# # print(np.array(Image.open(image_name)))\n",
    "\n",
    "# pred_img_np = data[1].numpy()\n",
    "# print(np.unique(pred_img_np))\n",
    "# print(len(np.unique(pred_img_np)))\n",
    "# pred_img_np = (pred_img_np * 255).astype(np.int8)\n",
    "# pred_img = Image.new('P', (pred_img_np.shape[1], pred_img_np.shape[0]))\n",
    "# palettes = get_palette(\"sem_seg\")\n",
    "# pred_img.putpalette(palettes)\n",
    "# pred_img.putdata(pred_img_np.ravel().tolist())\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(18, 12))  \n",
    "\n",
    "# plt.subplot(3,1,1)\n",
    "# plt.imshow(Image.open(image_name))\n",
    "# plt.title('Img')\n",
    "\n",
    "# plt.subplot(3, 1, 2)  \n",
    "# plt.imshow(data[0].permute(1,2,0).detach().numpy())  \n",
    "# plt.title('Original Image')\n",
    "\n",
    "\n",
    "# plt.subplot(3, 1, 3)  \n",
    "# plt.imshow(pred_img_np)  \n",
    "# plt.title('Predicted Mask')  \n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 512, 1024])\n"
     ]
    }
   ],
   "source": [
    "# from mmengine.dataset import Compose\n",
    "\n",
    "# cfg = Config.fromfile(config_file)\n",
    "# transform = Compose(cfg.train_pipeline)\n",
    "\n",
    "# data = transform(dict(img_path=image_name))\n",
    "\n",
    "# print(data[\"inputs\"].shape)\n",
    "\n",
    "# plt.imshow(data[\"inputs\"].permute(1,2,0).detach().numpy()/255)  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drivable-kJxmeTfE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
