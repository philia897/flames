{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"hjueyhO-yrXO"},"outputs":[],"source":["# !unzip -n -q /content/drive/MyDrive/Colab/DrivableArea/data/bdd100k_drivable_labels_trainval.zip -d /content/drive/MyDrive/Colab/DrivableArea/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hdcJs9So1PBA"},"outputs":[],"source":["# !7za x /content/drive/MyDrive/Colab/DrivableArea/data/bdd100k_drivable_labels_trainval.zip\n","# !cp --progress -r /content/bdd100k /content/drive/MyDrive/Colab/DrivableArea\n","# ! du -h /content/bdd100k/"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":55067,"status":"ok","timestamp":1681557824692,"user":{"displayName":"Zekun WANG","userId":"14157621543012677102"},"user_tz":-480},"id":"UyCWw_EvXxwR","outputId":"1f2832e8-f8d7-4162-94c2-d778c770d7e6"},"outputs":[],"source":["# ! wget https://dl.cv.ethz.ch/bdd100k/drivable/models/fcn_r50-d8_769x769_40k_drivable_bdd100k.pth\n","# ! pip install mmsegmentation\n","# # ! pip install mmcv-full\n","# !pip install -U openmim\n","# !mim install mmengine\n","# !mim install mmcv"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/plain":["0"]},"execution_count":13,"metadata":{},"output_type":"execute_result"},{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["import gc\n","import torch\n","torch.cuda.empty_cache()\n","gc.collect()"]},{"cell_type":"markdown","metadata":{"id":"mrWW7T4dKVHj"},"source":["## Set params"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":1237,"status":"ok","timestamp":1681557825923,"user":{"displayName":"Zekun WANG","userId":"14157621543012677102"},"user_tz":-480},"id":"ZTRODuUuKUXz"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["BATCH_SIZE = 4\n","NUM_EPOCHS = 5\n","LR = 0.0001\n","\n","STORE_MODEL_NAME = \"deeplabv3_backbone_refined_benchmark2\"\n","checkpoint_file = \"/home/zekun/drivable/outputs/deeplabv3_backbone_refined_benchmark-20230427_225904.pth\"\n","config_file = \"/home/zekun/drivable/models/config-deeplabv3.py\"\n","\n","\n","condition = {\n","    \"weather\": [\"clear\", \"undefined\", \"rainy\", \"snowy\", \"overcast\", \"partly cloudy\", \"foggy\"],  \n","    # \"clear\", \"undefined\", \"rainy\", \"snowy\", \"overcast\", \"partly cloudy\", \"foggy\"\n","    \"timeofday\": [\"daytime\", \"undefined\", \"night\", \"dawn/dusk\"],   \n","    # \"daytime\", \"undefined\", \"night\", \"dawn/dusk\"\n","    \"scene\": [\"tunnel\", \"residential\", \"parking lot\", \"undefined\", \"city street\", \"gas stations\", \"highway\"],  \n","    # \"tunnel\", \"residential\", \"parking lot\", \"undefined\", \"city street\", \"gas stations\", \"highway\"\n","}\n","# condition = None\n","\n","sample_limit = 0\n","\n","# output_size = (769,769)\n","output_size = (512,1024)\n","\n","import sys\n","import os\n","# sys.path.append('/content/drive/MyDrive/Colab/DrivableArea') # <= change path where you save code\n","BASE_PATH = \"./\"\n","OUTPUT_DIR = \"./outputs\"\n","os.makedirs(OUTPUT_DIR, exist_ok=True)\n","\n","import torch\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(DEVICE)"]},{"cell_type":"markdown","metadata":{"id":"HXNOeyKpG9zG"},"source":["## Get Images and load to dataloader"]},{"cell_type":"markdown","metadata":{"id":"F0Hy449PY6Jx"},"source":["### Dataset definition"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":800,"status":"ok","timestamp":1681557826716,"user":{"displayName":"Zekun WANG","userId":"14157621543012677102"},"user_tz":-480},"id":"qYa60Uh2H7pj"},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset\n","from torchvision import transforms\n","from PIL import Image\n","import os\n","from pathlib import Path\n","from importlib import reload\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","class BDD100kDataset(Dataset):\n","    def __init__(self, data_fns, msk_fn, split='train', transform=None, transform2=None):\n","        super(BDD100kDataset, self).__init__()\n","        # assert split in ['train', 'val', 'test'], \"Invalid split provided. Expected 'train', 'val' or 'test'\"\n","        \n","        self.image_fns = data_fns\n","        self.msk_fn = msk_fn\n","        self.split = split\n","        self.transform = transform\n","        self.transform2 = transform2\n","        \n","        # Check that image file names and label file names match\n","        # assert len(self.image_file_names) == len(self.label_file_names), \"Number of images and labels do not match\"\n","        self.num_samples = len(self.image_fns)\n","    \n","    def __getitem__(self, index):\n","        # Load image and label\n","        image = Image.open(self.image_fns[index])\n","        label = Image.open(self.msk_fn(self.image_fns[index]))\n","        \n","        # Apply transformations if provided\n","        if self.transform is not None:\n","            image = self.transform(image)\n","\n","        if self.transform2 is not None:\n","            label = self.transform2(label)\n","        \n","        # Convert label to tensor and convert from RGB to single channel (grayscale)\n","        label = torch.tensor(np.array(label)*255, dtype=torch.int64)\n","        label = torch.nn.functional.one_hot(label, num_classes=3).permute(2, 0, 1).float()\n","        \n","        return image, label\n","    \n","    def __len__(self):\n","        return self.num_samples"]},{"cell_type":"markdown","metadata":{"id":"HIOqCuKPZDHG"},"source":["### Get images"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1681557826717,"user":{"displayName":"Zekun WANG","userId":"14157621543012677102"},"user_tz":-480},"id":"KlD0wWSdGssR"},"outputs":[],"source":["IMAGE_PATH = os.path.join(\"data\", \"bdd100k\", \"images\", \"100k\")\n","IMAGE_PATH_TRAIN = os.path.join(IMAGE_PATH, \"train\")\n","IMAGE_PATH_VAL = os.path.join(IMAGE_PATH, \"val\")\n","\n","LABEL_PATH = os.path.join(\"data\", \"bdd100k\", \"labels\", \"drivable\", \"masks\")\n","LABEL_PATH_TRAIN = os.path.join(LABEL_PATH, \"train\")\n","LABEL_PATH_VAL = os.path.join(LABEL_PATH, \"val\")\n","\n","msk_fn_train = lambda fn : fn.replace(IMAGE_PATH_TRAIN, LABEL_PATH_TRAIN).replace(\"jpg\", \"png\")\n","msk_fn_val = lambda fn : fn.replace(IMAGE_PATH_VAL, LABEL_PATH_VAL).replace(\"jpg\", \"png\")"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":683,"status":"ok","timestamp":1681557827395,"user":{"displayName":"Zekun WANG","userId":"14157621543012677102"},"user_tz":-480},"id":"Hxy0VuqDv9eh","outputId":"eb701c96-7720-458b-be35-c3f7d930cda5"},"outputs":[{"name":"stdout","output_type":"stream","text":["train img: 69863\n","val img: 10000\n","data/bdd100k/images/100k/train/0000f77c-62c2a288.jpg\n","data/bdd100k/labels/drivable/masks/train/0000f77c-62c2a288.png\n"]}],"source":["if condition == None:\n","    train_fns = [str(f) for f in Path(IMAGE_PATH_TRAIN).rglob(\"*.jpg\")]\n","    val_fns = [str(f) for f in Path(IMAGE_PATH_VAL).rglob(\"*.jpg\")]\n","else:\n","    # Load the JSON file\n","    import json\n","    with open(f'{BASE_PATH}/data/bdd100k/labels/drivable/bdd100k_labels_images_attributes_train.json') as f:\n","        data = json.load(f)\n","\n","    # Extract the desired fields from the data\n","    result = []\n","    for entry in data:\n","        if entry[\"attributes\"][\"weather\"] not in condition[\"weather\"]:\n","            continue\n","        if entry[\"attributes\"][\"timeofday\"] not in condition[\"timeofday\"]:\n","            continue\n","        if entry[\"attributes\"][\"scene\"] not in condition[\"scene\"]:\n","            continue\n","        result.append(os.path.join(IMAGE_PATH_TRAIN, entry[\"name\"]))\n","\n","    train_fns = result\n","\n","    # Load the JSON file\n","    with open(f'{BASE_PATH}/data/bdd100k/labels/drivable/bdd100k_labels_images_attributes_val.json') as f:\n","        data = json.load(f)\n","\n","    # Extract the desired fields from the data\n","    result = []\n","    for entry in data:\n","        if entry[\"attributes\"][\"weather\"] not in condition[\"weather\"]:\n","            continue\n","        if entry[\"attributes\"][\"timeofday\"] not in condition[\"timeofday\"]:\n","            continue\n","        if entry[\"attributes\"][\"scene\"] not in condition[\"scene\"]:\n","            continue\n","        result.append(os.path.join(IMAGE_PATH_VAL, entry[\"name\"]))\n","\n","    # print(result[1])\n","    # print(len(result))\n","\n","    val_fns = result\n","\n","import random\n","if sample_limit != 0:\n","    train_fns = random.sample(train_fns, min(sample_limit, len(train_fns)))\n","    val_fns = random.sample(val_fns, min(int(sample_limit/10), len(val_fns)))\n","\n","print(f\"train img: {len(train_fns)}\")\n","print(f\"val img: {len(val_fns)}\")\n","\n","num_train_samples = len(train_fns)\n","num_val_samples = len(val_fns)\n","\n","print(train_fns[1])\n","print(msk_fn_train(train_fns[1]))"]},{"cell_type":"markdown","metadata":{"id":"NGFmG-HMdB3B"},"source":["### Create DataLoaders"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1681557827396,"user":{"displayName":"Zekun WANG","userId":"14157621543012677102"},"user_tz":-480},"id":"Z-uB92MoJ9ZS","outputId":"c8aea5e0-456e-4bb2-9614-0ddb28b5272c"},"outputs":[{"name":"stdout","output_type":"stream","text":["train_loader: 17466\n","val_loader: 2500\n","torch.Size([3, 512, 1024]) torch.Size([3, 512, 1024])\n","[0. 1.]\n"]}],"source":["from torch.utils.data import DataLoader\n","\n","# Define transformation to be applied to both images and labels\n","transform = transforms.Compose([\n","    transforms.Resize(output_size),\n","    transforms.ToTensor(),\n","    transforms.Lambda(lambda x: x.squeeze())\n","    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","transform2 = transforms.Compose([\n","    transforms.Resize(output_size),\n","    transforms.ToTensor(),\n","    transforms.Lambda(lambda x: x.squeeze())\n","])\n","\n","# Create training and validation datasets and data loaders\n","train_dataset = BDD100kDataset(train_fns, msk_fn_train, split='train', transform=transform, transform2=transform2)\n","val_dataset = BDD100kDataset(val_fns, msk_fn_val, split='val', transform=transform, transform2=transform2)\n","\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","\n","print(f\"train_loader: {len(train_loader)}\")\n","print(f\"val_loader: {len(val_loader)}\")\n","\n","img, lbl = train_dataset[1]\n","print(img.shape, lbl.shape)\n","print(np.unique(lbl.numpy()))"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1681557827398,"user":{"displayName":"Zekun WANG","userId":"14157621543012677102"},"user_tz":-480},"id":"8WQVHopIKxed"},"outputs":[],"source":["# NPLOT = 6\n","# idxs = np.argsort(np.random.rand(50))[:NPLOT]\n","# Y = 2\n","\n","# fig, axs = plt.subplots(Y, NPLOT, figsize=(NPLOT*5, Y*3))\n","# fig.subplots_adjust(top=1, bottom=0, left=0, right=1, hspace=0.2, wspace=0.01)\n","\n","# for i, idx in enumerate(idxs):\n","#   image, label = val_dataset[idx]\n","#   image = np.transpose(image.numpy(), (1, 2, 0))  # Add batch dimension\n","\n","#   # Pass the image through the model to get predicted output\n","#   # output = model(image)\n","#   # output = torch.argmax(output, dim=1).squeeze().detach().cpu().numpy()\n","#   output = torch.argmax(label, dim=0)\n","\n","#   # Convert the predicted output to a color-coded mask\n","#   mask = np.zeros((output.shape[0], output.shape[1], 3))\n","#   mask[output == 0] = [0, 1, 0]  # Direct\n","#   mask[output == 1] = [0, 0, 1]  # Alternative   \n","#   mask[output == 2] = [0, 0, 0]  # Background\n","\n","#   # Overlay the mask on top of the input image\n","#   alpha = 0.3\n","#   overlay = (alpha * mask + image)\n","\n","#   # Plot the input image and overlayed mask\n","#   axs[0, i].imshow(image)\n","#   axs[0, i].set_title('Image')\n","#   axs[0, i].axis('off')\n","\n","#   axs[1, i].imshow(overlay)\n","#   axs[1, i].set_title('Label')\n","#   axs[1, i].axis('off')\n","\n","# plt.show()"]},{"cell_type":"markdown","metadata":{"id":"fny6c-pLHDXC"},"source":["## Model Definition And Train"]},{"cell_type":"markdown","metadata":{"id":"4pMoi5Z3Op8I"},"source":["### Model Definition"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18010,"status":"ok","timestamp":1681557845401,"user":{"displayName":"Zekun WANG","userId":"14157621543012677102"},"user_tz":-480},"id":"8amxbSdnC6SR","outputId":"9d0ed23b-6e02-46ec-c531-e34705a51ab8"},"outputs":[{"name":"stdout","output_type":"stream","text":["(2, 0, 0)\n"]},{"name":"stderr","output_type":"stream","text":["/home/zekun/.local/share/virtualenvs/drivable-kJxmeTfE/lib/python3.10/site-packages/mmseg/models/builder.py:36: UserWarning: ``build_loss`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n","  warnings.warn('``build_loss`` would be deprecated soon, please use '\n","/home/zekun/.local/share/virtualenvs/drivable-kJxmeTfE/lib/python3.10/site-packages/mmseg/models/losses/cross_entropy_loss.py:235: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Loads checkpoint by local backend from path: /home/zekun/drivable/outputs/deeplabv3_backbone_refined_benchmark-20230427_225904.pth\n"]}],"source":["# checkpoint_file = '/content/fcn_r50-d8_769x769_40k_drivable_bdd100k.pth'\n","# checkpoint_file = f'outputs/{checkpoint_file_name}' # defined above\n","# img_path = '/content/bdd100k/images/100k/train/0000f77c-62c2a288.jpg'\n","\n","from mmseg.apis import inference_model, init_model, show_result_pyplot\n","import mmcv\n","print(mmcv.version.version_info)\n","from mmengine import runner\n","\n","backbone = init_model(config_file, device='cpu')\n","checkpoint = runner.load_checkpoint(backbone, checkpoint_file)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7159,"status":"ok","timestamp":1681557852537,"user":{"displayName":"Zekun WANG","userId":"14157621543012677102"},"user_tz":-480},"id":"e6nXuYY-C-M1","outputId":"5ef63148-0fb4-4482-ca21-876377c1a076"},"outputs":[],"source":["import models.modelInterface\n","reload(models.modelInterface)\n","from models.modelInterface import BDD100kModel\n","\n","model = BDD100kModel(num_classes=3, backbone=backbone, size=output_size)\n","# model = load_checkpoint(model, \"test-20230402_144923.pth\", OUTPUT_DIR)\n","model.to(DEVICE)"]},{"cell_type":"markdown","metadata":{"id":"LaH7QwGpdvQr"},"source":["### Model Train parameters"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":457,"status":"ok","timestamp":1681539271762,"user":{"displayName":"Zekun WANG","userId":"14157621543012677102"},"user_tz":-480},"id":"N5mJusEOOyxI"},"outputs":[],"source":["import datetime\n","import torch.optim as optim\n","from torch import nn\n","from lib.data.tools import load_checkpoint\n","\n","optimizer = optim.Adam(model.parameters(), lr=LR)\n","criterion = nn.CrossEntropyLoss()\n","\n","now = datetime.datetime.now()\n","timestamp = now.strftime(\"%Y%m%d_%H%M%S\")\n","stored_model_name = f\"{STORE_MODEL_NAME}-{timestamp}.pth\""]},{"cell_type":"markdown","metadata":{"id":"V11n_Kg7dzUW"},"source":["### Model Train"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":1963,"status":"ok","timestamp":1681537002715,"user":{"displayName":"Zekun WANG","userId":"14157621543012677102"},"user_tz":-480},"id":"aQoRCue7NUI8"},"outputs":[],"source":["import lib.runners\n","reload(lib.runners)\n","from lib.runners import train_epoch, valid_epoch\n","from lib.data.tools import save_model\n","\n","def train(train_data_loader, val_data_loader, model, optimizer, epoch_i, epoch_total, max_score):\n","  train_log = train_epoch(\n","      model=model,\n","      optimizer=optimizer,\n","      criterion=criterion,\n","      dataloader=train_data_loader,\n","      device=DEVICE\n","  )\n","  valid_logs = valid_epoch(\n","      model=model,\n","      criterion=criterion,\n","      dataloader=val_data_loader,\n","      device=DEVICE,\n","  )\n","  epoch_score = valid_logs[\"Score\"]  # Maybe print more information here for analysis\n","  if max_score < epoch_score:\n","      max_score = epoch_score\n","      save_model(\n","          model=model.backbone,\n","          epoch=epoch_i,\n","          best_score=max_score,\n","          model_name=stored_model_name,\n","          output_dir=OUTPUT_DIR,\n","      )\n","  save_model(\n","      model=model.backbone,\n","      epoch=epoch_i,\n","      best_score=epoch_score,\n","      model_name=\"tmp.pth\",\n","      output_dir=OUTPUT_DIR,\n","  )\n","  return max_score"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":502},"executionInfo":{"elapsed":1786953,"status":"error","timestamp":1681538798093,"user":{"displayName":"Zekun WANG","userId":"14157621543012677102"},"user_tz":-480},"id":"AbInKFMpjNDn","outputId":"5bdc0f4c-3004-4047-81c8-77a20bbaf681"},"outputs":[{"name":"stdout","output_type":"stream","text":["start at Thu May 11 16:28:08 2023\n","\n","Epoch: 0 / 5\n","-------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Train: 100%|██████████| 17466/17466 [3:09:56<00:00,  1.53it/s, Loss=0.0783, Score=0.756]  \n","Valid: 100%|██████████| 2500/2500 [09:45<00:00,  4.27it/s, Loss=0.0826, Score=0.737]\n"]},{"name":"stdout","output_type":"stream","text":["model saved\n","model saved\n","\n","Epoch 0 / 5:  11981.540621042252  unit time\n","\n","Epoch: 1 / 5\n","-------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Train: 100%|██████████| 17466/17466 [3:09:37<00:00,  1.54it/s, Loss=0.074, Score=0.766]   \n","Valid: 100%|██████████| 2500/2500 [09:46<00:00,  4.26it/s, Loss=0.0812, Score=0.741]\n"]},{"name":"stdout","output_type":"stream","text":["model saved\n","model saved\n","\n","Epoch 1 / 5:  11964.018610715866  unit time\n","\n","Epoch: 2 / 5\n","-------------------------------\n"]},{"name":"stderr","output_type":"stream","text":["Train:   1%|▏         | 260/17466 [02:50<3:08:01,  1.53it/s, Loss=0.0712, Score=0.77] \n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[10], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mEpoch: \u001b[39m\u001b[39m{\u001b[39;00mepoch_i\u001b[39m}\u001b[39;00m\u001b[39m / \u001b[39m\u001b[39m{\u001b[39;00mNUM_EPOCHS\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m-------------------------------\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m t1 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> 13\u001b[0m max_score \u001b[39m=\u001b[39m train(train_loader, val_loader, model, optimizer, epoch_i, NUM_EPOCHS, max_score)\n\u001b[1;32m     14\u001b[0m t2 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     15\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch_i\u001b[39m}\u001b[39;00m\u001b[39m / \u001b[39m\u001b[39m{\u001b[39;00mNUM_EPOCHS\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m, t2\u001b[39m-\u001b[39mt1, \u001b[39m\"\u001b[39m\u001b[39m unit time\u001b[39m\u001b[39m\"\u001b[39m)\n","Cell \u001b[0;32mIn[9], line 7\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_data_loader, val_data_loader, model, optimizer, epoch_i, epoch_total, max_score)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(train_data_loader, val_data_loader, model, optimizer, epoch_i, epoch_total, max_score):\n\u001b[0;32m----> 7\u001b[0m   train_log \u001b[39m=\u001b[39m train_epoch(\n\u001b[1;32m      8\u001b[0m       model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m      9\u001b[0m       optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[1;32m     10\u001b[0m       criterion\u001b[39m=\u001b[39;49mcriterion,\n\u001b[1;32m     11\u001b[0m       dataloader\u001b[39m=\u001b[39;49mtrain_data_loader,\n\u001b[1;32m     12\u001b[0m       device\u001b[39m=\u001b[39;49mDEVICE\n\u001b[1;32m     13\u001b[0m   )\n\u001b[1;32m     14\u001b[0m   valid_logs \u001b[39m=\u001b[39m valid_epoch(\n\u001b[1;32m     15\u001b[0m       model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m     16\u001b[0m       criterion\u001b[39m=\u001b[39mcriterion,\n\u001b[1;32m     17\u001b[0m       dataloader\u001b[39m=\u001b[39mval_data_loader,\n\u001b[1;32m     18\u001b[0m       device\u001b[39m=\u001b[39mDEVICE,\n\u001b[1;32m     19\u001b[0m   )\n\u001b[1;32m     20\u001b[0m   epoch_score \u001b[39m=\u001b[39m valid_logs[\u001b[39m\"\u001b[39m\u001b[39mScore\u001b[39m\u001b[39m\"\u001b[39m]  \u001b[39m# Maybe print more information here for analysis\u001b[39;00m\n","File \u001b[0;32m~/drivable/lib/runners.py:91\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, optimizer, criterion, dataloader, device)\u001b[0m\n\u001b[1;32m     88\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     89\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m---> 91\u001b[0m loss_meter\u001b[39m.\u001b[39mupdate(loss\u001b[39m.\u001b[39;49mitem(), n\u001b[39m=\u001b[39mn)\n\u001b[1;32m     93\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m     94\u001b[0m     avg, scores \u001b[39m=\u001b[39m metric(outputs, y)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]},{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["import time\n","\n","start = time.time()\n","print(f\"start at {time.ctime()}\")\n","\n","model.to(DEVICE).train()\n","# epoch_i = 1\n","max_score = 0\n","for epoch_i in range(NUM_EPOCHS):\n","    # training\n","    print(f\"\\nEpoch: {epoch_i} / {NUM_EPOCHS}\\n-------------------------------\")\n","    t1 = time.time()\n","    max_score = train(train_loader, val_loader, model, optimizer, epoch_i, NUM_EPOCHS, max_score)\n","    t2 = time.time()\n","    print(f\"\\nEpoch {epoch_i} / {NUM_EPOCHS}: \", t2-t1, \" unit time\")\n","\n","print(\"Elapsed time: {:.3f} min\".format((time.time() - start) / 60.0))"]},{"cell_type":"markdown","metadata":{"id":"VjFoyyaJd4gZ"},"source":["### Model Test"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":433},"executionInfo":{"elapsed":60202,"status":"error","timestamp":1681539344519,"user":{"displayName":"Zekun WANG","userId":"14157621543012677102"},"user_tz":-480},"id":"m686CbmCDZSE","outputId":"c2bf794a-ecf7-417b-d0b5-22e0fc4a9776"},"outputs":[{"name":"stderr","output_type":"stream","text":["Valid: 100%|██████████| 2500/2500 [09:28<00:00,  4.40it/s, Loss=0.136, Score=0.654]"]},{"name":"stdout","output_type":"stream","text":["{'Loss': 0.13587871412411331, 'Score': 0.6538538311097193}\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["model.eval()\n","\n","valid_logs = valid_epoch(\n","    model=model,\n","    criterion=criterion,\n","    dataloader=val_loader,\n","    device=DEVICE,\n",")\n","\n","print(valid_logs)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":588,"output_embedded_package_id":"1Ak9JlcgYuw3h7ZfiMlqWiIal83u1xS0T"},"executionInfo":{"elapsed":14671,"status":"ok","timestamp":1681539362244,"user":{"displayName":"Zekun WANG","userId":"14157621543012677102"},"user_tz":-480},"id":"4Tr1Bua4slPp","outputId":"5dadb005-c944-4ee9-deb1-1c962cabc02c"},"outputs":[],"source":["NPLOT = 6\n","idxs = np.argsort(np.random.rand(50))[:NPLOT]\n","Y = 3\n","\n","fig, axs = plt.subplots(Y, NPLOT, figsize=(NPLOT*3, Y*3))\n","fig.subplots_adjust(top=1, bottom=0, left=0, right=1, hspace=0.2, wspace=0.01)\n","\n","# model.to(DEVICE)\n","model.eval()\n","\n","for i, idx in enumerate(idxs):\n","  image, label = val_dataset[idx]\n","\n","  # Pass the image through the model to get predicted output\n","  # output = model(image)\n","  # output = torch.argmax(output, dim=1).squeeze().detach().cpu().numpy()\n","  with torch.no_grad():\n","    output = torch.argmax(label, dim=0)\n","    pred = model(image.unsqueeze(0).to(DEVICE))\n","    # pred = torch.nn.Upsample(scale_factor=8, mode='bilinear', align_corners=False)\n","    # print(pred.shape)\n","    # print(np.transpose(label.squeeze().numpy(), (1,2,0)))\n","    # print(np.transpose(pred.squeeze().detach().cpu().numpy(), (1, 2, 0)))\n","    pred = torch.argmax(pred, dim=1).squeeze().detach().cpu().numpy()\n","    \n","\n","  image = np.transpose(image.numpy(), (1, 2, 0))  # Add batch dimension\n","\n","  # Convert the predicted output to a color-coded mask\n","  mask = np.zeros((output.shape[0], output.shape[1], 3))\n","  mask[output == 0] = [0, 1, 0]  # Direct\n","  mask[output == 1] = [0, 0, 1]  # Alternative   \n","  mask[output == 2] = [0, 0, 0]  # Background\n","\n","  # Overlay the mask on top of the input image\n","  alpha = 0.3\n","  overlay = (alpha * mask + image)\n","\n","  # Convert the predicted output to a color-coded mask\n","  mask[pred == 0] = [0, 1, 0]  # Direct\n","  mask[pred == 1] = [0, 0, 1]  # Alternative   \n","  mask[pred == 2] = [0, 0, 0]  # Background\n","  overlay2 = (alpha * mask + image)\n","\n","  # Plot the input image and overlayed mask\n","  axs[0, i].imshow(image)\n","  axs[0, i].set_title('Image')\n","  axs[0, i].axis('off')\n","\n","  axs[1, i].imshow(overlay)\n","  axs[1, i].set_title('Label')\n","  axs[1, i].axis('off')\n","\n","  axs[2, i].imshow(overlay2)\n","  axs[2, i].set_title('Pred')\n","  axs[2, i].axis('off')\n","\n","plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Predict Masks"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Predicting: 100%|██████████| 660/660 [00:39<00:00, 16.70it/s]\n"]}],"source":["TMP_DIR = \"tmp\"\n","\n","import shutil\n","from tqdm import tqdm\n","shutil.rmtree(TMP_DIR)\n","os.makedirs(TMP_DIR, exist_ok=True)\n","os.makedirs(f\"{TMP_DIR}/mask\", exist_ok=True)\n","os.makedirs(f\"{TMP_DIR}/pred\", exist_ok=True)\n","\n","from torch.utils.data import DataLoader\n","import torchvision.transforms.functional as TF\n","\n","# Define dataloader for validation dataset\n","val_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n","\n","# Set model to evaluation mode\n","model.eval()\n","# model.to(DEVICE)\n","\n","# Define transform to resize predicted mask to original image size\n","resize = transforms.Resize((720, 1280))\n","\n","# Iterate over validation dataset\n","iterator = tqdm(val_dataloader, desc=\"Predicting\")\n","for i, (image, _) in enumerate(iterator):\n","    # Move data to GPU if available\n","    image = image.to(DEVICE)\n","    # print(image.device)\n","\n","    # Get predicted mask from model\n","    with torch.no_grad():\n","        output = model(image)\n","        mask = output.argmax(dim=1)\n","\n","    # Resize mask to original image size and convert to PIL image\n","    mask = resize(mask.unsqueeze(1))\n","    mask_pil = transforms.ToPILImage()(mask.to(torch.uint8).squeeze().cpu())\n","\n","    # print(mask_pil.size)\n","    \n","    msk_path = msk_fn_val(val_fns[i])\n","    name = os.path.basename(msk_path)\n","    shutil.copy(msk_path, f\"{TMP_DIR}/mask/\")\n","    # Save resized mask to disk with the same name as the input image\n","    mask_pil.save(f'{TMP_DIR}/pred/{name}')\n","    # break"]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[2023-04-28 09:01:06,652 seg.py:142 evaluate_segmentation] Found 660 results\n","[2023-04-28 09:01:06,653 seg.py:155 evaluate_segmentation] evaluating...\n","[2023-04-28 09:01:06,654 utils.py:100 reorder_preds] 0 images are missed in the prediction.\n","100%|████████████████████████████████████| 660/660 [00:00<00:00, 1020361.46it/s]\n","[2023-04-28 09:01:09,296 seg.py:173 evaluate_segmentation] accumulating...\n","[2023-04-28 09:01:09,297 seg.py:201 evaluate_segmentation] GT id set [0,1]\n","[2023-04-28 09:01:09,297 run.py:285 run] \n","             IoU  Acc\n","---------------------\n","direct      84.4 94.8\n","alternative 56.4 82.4\n","---------------------\n","AVERAGE     70.4 88.6\n","\n","\n"]}],"source":["! python3 -m bdd100k.bdd100k.eval.run -t drivable -g ./tmp/mask/ -r ./tmp/pred/ --out-file ./tmp/result.json\n","\n","import json\n","\n","with open(f'{TMP_DIR}/result.json') as f:\n","    data = json.load(f)\n","    print(f.read())\n","\n","with open(f'./bdd100k-eval-result.json', \"r\") as f:\n","    results = json.load(f)\n","    results.append({\n","        \"model\": STORE_MODEL_NAME, \n","        \"condition\": condition,\n","        \"val samples\": num_val_samples, \n","        \"metrics\": data})\n","\n","with open(f'./bdd100k-eval-result.json', \"w\") as f:\n","    json.dump(results, f, indent=4)"]},{"cell_type":"markdown","metadata":{},"source":["## Simple Test"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1681557852538,"user":{"displayName":"Zekun WANG","userId":"14157621543012677102"},"user_tz":-480},"id":"k0XG8mfITQZy","outputId":"db32b31c-b78c-474b-b30e-72792b89dfb3"},"outputs":[{"name":"stdout","output_type":"stream","text":["4 3 4 4 cuda:0\n","cuda:0 cuda:0\n","tensor([[[0., 0., 0., 0.],\n","         [1., 0., 0., 0.],\n","         [1., 0., 0., 1.],\n","         [1., 0., 0., 0.]],\n","\n","        [[1., 1., 0., 1.],\n","         [0., 0., 0., 1.],\n","         [0., 1., 0., 0.],\n","         [0., 1., 1., 1.]],\n","\n","        [[0., 0., 1., 0.],\n","         [0., 1., 1., 0.],\n","         [0., 0., 1., 0.],\n","         [0., 0., 0., 0.]]], device='cuda:0')\n"]}],"source":["import torch\n","\n","# assuming batch size of 4, 3 classes, and 256x256 output size\n","batch_size = 4\n","num_classes = 3\n","output_size = (4, 4)\n","\n","# create some random predictions\n","predictions = torch.randn(batch_size, num_classes, *output_size).to(\"cuda\")\n","# predictions = predictions_cpu.to(device=\"cuda\")\n","print(*(predictions.shape), predictions.device)\n","\n","# convert predictions to one-hot format\n","one_hot = torch.zeros(batch_size, num_classes, *output_size).to(\"cuda\")\n","max_idx = torch.argmax(predictions, dim=1)\n","print(one_hot.device, max_idx.device)\n","one_hot.scatter_(1, max_idx.unsqueeze(1), 1)\n","print(one_hot[0])\n","\n","# print(torch.softmax(one_hot, dim=1)[0])"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMCV/Q6g5Czw00ebGeXFItx","mount_file_id":"1ggYAUrSdJ6JUESY6UPSL4dd8aOMW1O3F","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"}},"nbformat":4,"nbformat_minor":0}
